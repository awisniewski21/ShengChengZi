{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e405b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive/\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b59fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from diffusers import DDPMPipeline, DDPMScheduler, DPMSolverMultistepScheduler, UNet2DModel  # NOQA\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from config.rand2char_config import TrainingConfigRand2Char\n",
    "from utils.eval_utils import DiffusionPipelineRand2Char\n",
    "from utils.train_utils import get_dataloader\n",
    "from utils.utils import get_repo_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd1ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db22da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_IMAGE_DIR = get_repo_dir() / Path(\"data/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69594e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = TrainingConfigRand2Char(\n",
    "    image_size=32,\n",
    "    train_batch_size=32,\n",
    "    eval_batch_size=16,\n",
    "    encoder_dim=512,\n",
    "    save_image_epochs=1,\n",
    "    save_model_epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13c7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = get_dataloader(cfg, ROOT_IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6eb17ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Model Parameters: 6,005,825\n"
     ]
    }
   ],
   "source": [
    "model = UNet2DModel(\n",
    "    sample_size=cfg.image_size,\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    layers_per_block=2,\n",
    "    block_out_channels=(32, 64, 128, 128),\n",
    "    down_block_types=(\"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\", \"DownBlock2D\"),\n",
    "    up_block_types=(\"UpBlock2D\", \"UpBlock2D\", \"UpBlock2D\", \"UpBlock2D\"),\n",
    ")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total Model Parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4712cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=cfg.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=cfg.lr_warmup_steps,\n",
    "    num_training_steps=len(train_dataloader) * cfg.num_epochs,\n",
    ")\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "inference_scheduler = DPMSolverMultistepScheduler(num_train_timesteps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63ba39b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(\n",
    "    cfg: TrainingConfigRand2Char,\n",
    "    train_dataloader: DataLoader,\n",
    "    model: UNet2DModel,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    lr_scheduler: torch.optim.lr_scheduler.LRScheduler,\n",
    "    noise_scheduler: DDPMScheduler,\n",
    "    inference_scheduler: DPMSolverMultistepScheduler,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Tensorboard logging\n",
    "    if cfg.output_dir is not None:\n",
    "        os.makedirs(cfg.output_dir, exist_ok=True)\n",
    "    run_name = f\"train_rand2char_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    log_dir = str(Path(cfg.output_dir) / \"logs\" / run_name)\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    # Train loop\n",
    "    global_step = 0\n",
    "    for epoch in range(cfg.num_epochs):\n",
    "        pbar = tqdm(train_dataloader, desc=f\"Epoch {epoch}\")\n",
    "\n",
    "        model.train()\n",
    "        for b_imgs in pbar:\n",
    "            b_imgs = b_imgs.to(device)\n",
    "\n",
    "            noise = torch.randn_like(b_imgs)\n",
    "            timesteps = torch.randint(0, noise_scheduler.config.num_train_timesteps, (b_imgs.shape[0],), device=device).long()\n",
    "            b_imgs_noisy = noise_scheduler.add_noise(b_imgs, noise, timesteps)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            noise_pred = model(b_imgs_noisy, timesteps).sample\n",
    "            loss = torch.nn.functional.mse_loss(noise_pred, noise)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            logs = {\"loss\": loss.detach().item(), \"lr\": lr_scheduler.get_last_lr()[0], \"step\": global_step}\n",
    "            pbar.set_postfix(**logs)\n",
    "            writer.add_scalar(\"Loss/train\", logs[\"loss\"], global_step)\n",
    "            writer.add_scalar(\"LR\", logs[\"lr\"], global_step)\n",
    "            global_step += 1\n",
    "\n",
    "        model.eval()\n",
    "        pipeline = DiffusionPipelineRand2Char(unet=model, scheduler=noise_scheduler)\n",
    "        pipeline.set_progress_bar_config(desc=\"Generating evaluation image grid...\")\n",
    "\n",
    "        # Save model checkpoint\n",
    "        if epoch % cfg.save_model_epochs == 0 or epoch == cfg.num_epochs - 1:\n",
    "            if epoch > 0:\n",
    "                pipeline.save_pretrained(str(Path(cfg.output_dir) / \"models\" / run_name / f\"epoch_{epoch}\"))\n",
    "                pipeline.save_pretrained(str(Path(cfg.output_dir) / \"models\" / run_name / f\"latest\"))\n",
    "\n",
    "        # Evaluate and log images\n",
    "        if epoch % cfg.save_image_epochs == 0 or epoch == cfg.num_epochs - 1:\n",
    "            img_grid = pipeline.evaluate_texts_to_image_grid(batch_size=cfg.eval_batch_size, output_type=\"numpy\", seed=cfg.seed)\n",
    "            writer.add_images(\"eval_imgs\", img_grid, global_step, dataformats=\"NWHC\")\n",
    "        writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2d69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd247fb3af7f440d93a89bc06a2c8e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 0:   0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84aae97f93d745c9ab39b4006eee8c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating evaluation image grid...:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17bfdfeaeca42e68465f69948d01ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfb0b766b1b34eae89da188a28ee1261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating evaluation image grid...:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e890ef26a67541a8b3af6101c29c4483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406a088d5b9b4d68b8b8e59d54e74d01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating evaluation image grid...:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f764796a1e0541b38c9c50fe76c56315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c2e72f6b0134eae85a4ca00008eff8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating evaluation image grid...:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d195720e7d42d09064e5ffecd9809e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766e7c54fb2645099a025233c2bcb5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating evaluation image grid...:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train model\n",
    "train_loop(cfg, train_dataloader, model, optimizer, lr_scheduler, noise_scheduler, inference_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d59713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from line_profiler import LineProfiler\n",
    "# lp = LineProfiler()\n",
    "# lp.add_function(train_loop)\n",
    "# lp.run(\"train_loop(cfg, train_dataloader, model, optimizer, lr_scheduler, noise_scheduler, inference_scheduler)\")\n",
    "# lp.print_stats(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf70a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
